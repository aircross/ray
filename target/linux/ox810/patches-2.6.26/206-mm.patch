diff -Naur linux-2.6.24.4/mm/filemap.c linux-2.6.24.4-oxnas/mm/filemap.c
--- linux-2.6.24.4/mm/filemap.c	2008-03-25 02:49:18.000000000 +0800
+++ linux-2.6.24.4-oxnas/mm/filemap.c	2009-05-08 16:23:38.000000000 +0800
@@ -42,6 +42,8 @@
 
 #include <asm/mman.h>
 
+#include <asm/plat-oxnas/dma.h>
+
 static ssize_t
 generic_file_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 	loff_t offset, unsigned long nr_segs);
@@ -884,12 +886,31 @@
 	unsigned int prev_offset;
 	int error;
 
-	index = *ppos >> PAGE_CACHE_SHIFT;
+    // Page table mod's
+#define MAX_QUEUED_PAGES (65536/PAGE_CACHE_SIZE)
+	// Create the page table
+	struct page* page_table[MAX_QUEUED_PAGES];
+	pgoff_t start_index;
+	unsigned long loop_offset;
+	unsigned long transfer_count;
+	unsigned long start_desc_count;
+	unsigned long index_count;
+	unsigned long desc_remaining;     
+
+
+    index = *ppos >> PAGE_CACHE_SHIFT;
 	prev_index = ra->prev_pos >> PAGE_CACHE_SHIFT;
 	prev_offset = ra->prev_pos & (PAGE_CACHE_SIZE-1);
 	last_index = (*ppos + desc->count + PAGE_CACHE_SIZE-1) >> PAGE_CACHE_SHIFT;
 	offset = *ppos & ~PAGE_CACHE_MASK;
 
+    // Page table mod's
+	start_index = index;
+	index_count = 0;
+	transfer_count = 0;
+	desc_remaining = desc->count;
+	loop_offset = offset;
+
 	for (;;) {
 		struct page *page;
 		pgoff_t end_index;
@@ -935,12 +956,12 @@
 		nr = PAGE_CACHE_SIZE;
 		if (index == end_index) {
 			nr = ((isize - 1) & ~PAGE_CACHE_MASK) + 1;
-			if (nr <= offset) {
+			if (nr <= loop_offset) {
 				page_cache_release(page);
 				goto out;
 			}
 		}
-		nr = nr - offset;
+		nr = nr - loop_offset;
 
 		/* If users can be writing to this page using arbitrary
 		 * virtual addresses, take care about potential aliasing
@@ -953,30 +974,84 @@
 		 * When a sequential read accesses a page several times,
 		 * only mark it as accessed the first time.
 		 */
-		if (prev_index != index || offset != prev_offset)
+		if (prev_index != index || loop_offset != prev_offset)
 			mark_page_accessed(page);
 		prev_index = index;
 
 		/*
 		 * Ok, we have the page, and it's up-to-date, so
-		 * now we can copy it to user space...
-		 *
-		 * The actor routine returns how many bytes were actually used..
-		 * NOTE! This may not be the same as how much of a user buffer
-		 * we filled up (we may be padding etc), so we can only update
-		 * "pos" here (the actor routine has to update the user buffer
-		 * pointers and the remaining count).
+		 * now we can mark it for copy it to user space...
 		 */
-		ret = actor(desc, page, offset, nr);
-		offset += ret;
-		index += offset >> PAGE_CACHE_SHIFT;
-		offset &= ~PAGE_CACHE_MASK;
-		prev_offset = offset;
+        page_table[index_count] = page;
 
-		page_cache_release(page);
-		if (ret == nr && desc->count)
-			continue;
-		goto out;
+        index_count++;
+
+        transfer_count += nr;
+
+        if (transfer_count >= desc->count) {            
+            loop_offset += desc_remaining;
+            index += loop_offset >> PAGE_CACHE_SHIFT;            
+            loop_offset &= ~PAGE_CACHE_MASK;
+            desc_remaining = 0;
+        } else {            
+            loop_offset = 0;
+            index++;
+            desc_remaining -= nr;
+        }
+        
+        prev_offset = loop_offset;
+        //ra.prev_offset = loop_offset;
+
+        /**
+         *  Do we have enough data in the pages so far, or enough
+         *  pages left, to satisfy the count specified in the descriptor ?
+         */
+        if ((transfer_count < desc->count) && (index <= end_index) && (index_count < MAX_QUEUED_PAGES)) {
+            continue;
+        }
+        
+    /*
+     * The actor routine returns how many bytes were actually used..
+     * NOTE! This may not be the same as how much of a user buffer
+     * we filled up (we may be padding etc), so we can only update
+     * "pos" here (the actor routine has to update the user buffer
+     * pointers and the remaining count).
+     */
+    
+    start_desc_count = desc->count;
+        
+    ret = actor(desc, page_table, offset, transfer_count);
+
+    /*
+     * Some debug to test if our assumptions about the transfer length are correct
+     * We shouldn't see this message under normal execution
+     */
+
+    if ((start_desc_count != ret) && (transfer_count != ret)) {
+        printk("desc_count %#x, ret %#x, transfer_count %#x\n",start_desc_count,ret, transfer_count);
+    }
+    
+    offset += ret;
+    index = start_index + (offset >> PAGE_CACHE_SHIFT);
+    
+    offset &= ~PAGE_CACHE_MASK;
+    //ra.prev_offset = offset;
+
+    while (index_count) {
+        index_count--;
+        page_cache_release(page_table[index_count]);
+    }
+    
+    if (ret == transfer_count && desc->count) {
+        // should probably think of what to do...
+        index_count = 0;
+        start_index = index;
+        transfer_count = 0;
+        loop_offset = offset;
+        desc_remaining = desc->count;
+        continue;
+    }
+    goto out;
 
 page_not_up_to_date:
 		/* Get exclusive access to the page ... */
@@ -1056,6 +1131,7 @@
 		goto readpage;
 	}
 
+
 out:
 	ra->prev_pos = prev_index;
 	ra->prev_pos <<= PAGE_CACHE_SHIFT;
@@ -1067,42 +1143,96 @@
 }
 EXPORT_SYMBOL(do_generic_mapping_read);
 
-int file_read_actor(read_descriptor_t *desc, struct page *page,
+int file_read_actor(read_descriptor_t *desc, struct page **page,
 			unsigned long offset, unsigned long size)
 {
 	char *kaddr;
 	unsigned long left, count = desc->count;
+    unsigned char* dst;
+    unsigned long ret_size;
+    
 
 	if (size > count)
 		size = count;
 
+    ret_size = size;
+    
+    dst = desc->arg.buf;
+
 	/*
 	 * Faults on the destination of a read are common, so do it before
 	 * taking the kmap.
 	 */
-	if (!fault_in_pages_writeable(desc->arg.buf, size)) {
-		kaddr = kmap_atomic(page, KM_USER0);
-		left = __copy_to_user_inatomic(desc->arg.buf,
-						kaddr + offset, size);
-		kunmap_atomic(kaddr, KM_USER0);
-		if (left == 0)
-			goto success;
-	}
+    while (size) {            
+        unsigned long psize = PAGE_CACHE_SIZE - offset;
+        struct page *page_it;
+        
+        psize = PAGE_CACHE_SIZE - offset;
+        if (size <= psize) {
+            psize = size;                
+        }
+
+        if  (fault_in_pages_writeable(dst, psize))
+            break;
+        
+        page_it = *page;
+        
+        kaddr = kmap_atomic(page_it, KM_USER0);
+        left = __copy_to_user_inatomic(dst,
+                                       kaddr + offset, psize);
+        kunmap_atomic(kaddr, KM_USE R0);
+        if (left != 0)  
+            break;  
+
+        size -= psize;            
+        page++;
+        offset += psize;
+        dst += psize;            
+        offset &= (PAGE_CACHE_SIZE - 1);
+    }
+
+    if (size == 0)
+        goto success;
+        
 
 	/* Do it the slow way */
-	kaddr = kmap(page);
-	left = __copy_to_user(desc->arg.buf, kaddr + offset, size);
-	kunmap(page);
 
-	if (left) {
-		size -= left;
-		desc->error = -EFAULT;
-	}
+    
+    while (size) {
+        unsigned long psize;
+        struct page *page_it;
+        
+        psize = PAGE_CACHE_SIZE - offset;
+        if (size <= psize) {
+            psize = size;                
+        }
+            
+
+        page_it = *page;
+
+        kaddr = kmap(page_it);
+        
+        left = __copy_to_user(dst, kaddr + offset, psize);
+        kunmap(page_it);
+
+        if (left) {
+            size -= left;
+            desc->error = -EFAULT;
+            break;            
+        }
+        page++;
+        offset += psize;
+        dst += psize;            
+        offset &= (PAGE_CACHE_SIZE - 1);
+        
+        size -= psize;
+    }
+
 success:
-	desc->count = count - size;
-	desc->written += size;
-	desc->arg.buf += size;
-	return size;
+	desc->count = count - ret_size;
+	desc->written += ret_size;
+	desc->arg.buf += ret_size;
+	return ret_size;
 }
 
 /*
@@ -1116,8 +1246,9 @@
  * properly initialized first). Returns appropriate error code that caller
  * should return or zero in case that write should be allowed.
  */
-int generic_segment_checks(const struct iovec *iov,
-			unsigned long *nr_segs, size_t *count, int access_flags)
+int generic_segment_checks_ex(const struct iovec *iov,
+			unsigned long *nr_segs, size_t *count, int access_flags,
+			int kernel)
 {
 	unsigned long   seg;
 	size_t cnt = 0;
@@ -1131,7 +1262,7 @@
 		cnt += iv->iov_len;
 		if (unlikely((ssize_t)(cnt|iv->iov_len) < 0))
 			return -EINVAL;
-		if (access_ok(access_flags, iv->iov_base, iv->iov_len))
+		if (kernel || access_ok(access_flags, iv->iov_base, iv->iov_len))
 			continue;
 		if (seg == 0)
 			return -EFAULT;
@@ -1142,6 +1273,13 @@
 	*count = cnt;
 	return 0;
 }
+EXPORT_SYMBOL(generic_segment_checks_ex);
+
+int generic_segment_checks(const struct iovec *iov,
+			unsigned long *nr_segs, size_t *count, int access_flags)
+{
+	return generic_segment_checks_ex(iov, nr_segs, count, access_flags, 0);
+}
 EXPORT_SYMBOL(generic_segment_checks);
 
 /**
@@ -1219,6 +1357,46 @@
 }
 EXPORT_SYMBOL(generic_file_aio_read);
 
+int file_send_actor(read_descriptor_t * desc, struct page **page, unsigned long offset, unsigned long size)
+{
+    ssize_t written;
+	unsigned long count = desc->count;
+	struct file *file = desc->arg.data;
+
+	if (size > count)
+		size = count;
+
+	written = file->f_op->sendpages(file, page, offset,
+				       size, &file->f_pos, size<count);
+	if (written < 0) {
+		desc->error = written;
+		written = 0;
+	}
+	desc->count = count - written;
+	desc->written += written;
+	return written;
+}
+
+ssize_t generic_file_sendfile(struct file *in_file, loff_t *ppos,
+			 size_t count, read_actor_t actor, void *target)
+{
+	read_descriptor_t desc;
+
+	if (!count)
+		return 0;
+
+	desc.written = 0;
+	desc.count = count;
+	desc.arg.data = target;
+	desc.error = 0;
+
+	do_generic_file_read(in_file, ppos, &desc, actor);
+	if (desc.written)
+		return desc.written;
+	return desc.error;
+}
+EXPORT_SYMBOL(generic_file_sendfile);
+
 static ssize_t
 do_readahead(struct address_space *mapping, struct file *filp,
 	     pgoff_t index, unsigned long nr)
@@ -1669,6 +1847,46 @@
 	return copied - left;
 }
 
+static void __iovec_copy_from_kernel(
+	char			    *vaddr,
+	const struct iovec  *iov,
+	size_t				 base,
+	size_t				 bytes,
+	oxnas_dma_channel_t *dma_chan)
+{
+//printk("__iovec_copy_from_kernel() Entered\n");
+	while (bytes) {
+		char *buf = iov->iov_base + base;
+		int   copy = min(bytes, iov->iov_len - base);
+
+		base = 0;
+
+		if (dma_chan) {
+//printk("src = %p, dst = %p, len = %d\n", (unsigned char *)virt_to_dma(0, buf), (unsigned char *)virt_to_dma(0, vaddr), copy);
+			if (oxnas_dma_set(dma_chan,
+							  (unsigned char *)virt_to_dma(0, buf),
+							  copy,
+							  (unsigned char *)virt_to_dma(0, vaddr), /* Needs DMA invalidation performed */
+							  OXNAS_DMA_MODE_INC,
+							  OXNAS_DMA_MODE_INC, 0, 1)) {
+				printk("DMA failed\n");
+				break;
+			} else {
+				/* Start DMA and poll for completion */
+				oxnas_dma_start(dma_chan);
+				while (oxnas_dma_is_active(dma_chan));
+			}
+		} else {
+			memcpy(vaddr, buf, copy);
+		}
+
+		bytes -= copy;
+		vaddr += copy;
+		iov++;
+	}
+//printk("__iovec_copy_from_kernel() Leaving\n");
+}
+
 /*
  * Copy as much as we can into the page and return the number of bytes which
  * were sucessfully copied.  If a fault is encountered then return the number of
@@ -1699,6 +1917,28 @@
 EXPORT_SYMBOL(iov_iter_copy_from_user_atomic);
 
 /*
+ * Copy as much as we can into the page and return the number of bytes which
+ * were sucessfully copied
+ */
+size_t iov_iter_copy_from_kernel_atomic(
+	struct page		    *page,
+	struct iov_iter     *i,
+	unsigned long 	     offset,
+	size_t 			     bytes,
+	oxnas_dma_channel_t *dma_chan)
+{
+	if (likely(i->nr_segs == 1)) {
+//printk("iov_iter_copy_from_kernel_atomic() Single segment\n");
+		memcpy(page_address(page) + offset, i->iov->iov_base + i->iov_offset, bytes);
+	} else {
+		__iovec_copy_from_kernel(page_address(page) + offset, i->iov, i->iov_offset, bytes, dma_chan);
+	}
+
+	return bytes;
+}
+EXPORT_SYMBOL(iov_iter_copy_from_kernel_atomic);
+
+/*
  * This has the same sideeffects and return value as
  * iov_iter_copy_from_user_atomic().
  * The difference is that it attempts to resolve faults.
@@ -2191,7 +2431,7 @@
 }
 
 static ssize_t generic_perform_write(struct file *file,
-				struct iov_iter *i, loff_t pos)
+				struct iov_iter *i, loff_t pos, int kernel, void *arg)
 {
 	struct address_space *mapping = file->f_mapping;
 	const struct address_space_operations *a_ops = mapping->a_ops;
@@ -2230,23 +2470,31 @@
 		 * to check that the address is actually valid, when atomic
 		 * usercopies are used, below.
 		 */
-		if (unlikely(iov_iter_fault_in_readable(i, bytes))) {
+		if (!kernel && unlikely(iov_iter_fault_in_readable(i, bytes))) {
 			status = -EFAULT;
 			break;
 		}
-
+//if (kernel) printk("generic_perform_write() Calling write_begin()\n");
 		status = a_ops->write_begin(file, mapping, pos, bytes, flags,
 						&page, &fsdata);
+//if (kernel) printk("generic_perform_write() Returned from write_begin() with status = %ld, page = %p\n", status, page);
 		if (unlikely(status))
 			break;
 
-		pagefault_disable();
-		copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);
-		pagefault_enable();
-		flush_dcache_page(page);
+		if (kernel) {
+			oxnas_dma_channel_t *dma_chan = (oxnas_dma_channel_t*)arg;
+			copied = iov_iter_copy_from_kernel_atomic(page, i, offset, bytes, dma_chan);
+		} else {
+			pagefault_disable();
+			copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);
+			pagefault_enable();
+			flush_dcache_page(page);
+		}
 
+//if (kernel) printk("generic_perform_write() Calling write_end(), copied = %d\n", copied);
 		status = a_ops->write_end(file, mapping, pos, bytes, copied,
 						page, fsdata);
+//if (kernel) printk("generic_perform_write() Returned from write_end() with status = %ld\n", status);
 		if (unlikely(status < 0))
 			break;
 		copied = status;
@@ -2278,9 +2526,9 @@
 }
 
 ssize_t
-generic_file_buffered_write(struct kiocb *iocb, const struct iovec *iov,
+generic_file_buffered_write_ex(struct kiocb *iocb, const struct iovec *iov,
 		unsigned long nr_segs, loff_t pos, loff_t *ppos,
-		size_t count, ssize_t written)
+		size_t count, ssize_t written, int kernel, void *arg)
 {
 	struct file *file = iocb->ki_filp;
 	struct address_space *mapping = file->f_mapping;
@@ -2290,11 +2538,13 @@
 	struct iov_iter i;
 
 	iov_iter_init(&i, iov, nr_segs, count, written);
-	if (a_ops->write_begin)
-		status = generic_perform_write(file, &i, pos);
-	else
+	if (a_ops->write_begin) {
+		status = generic_perform_write(file, &i, pos, kernel, arg);
+//if (kernel) printk("generic_file_buffered_write_ex() 1 status = %d\n", status);
+	} else {
 		status = generic_perform_write_2copy(file, &i, pos);
-
+//if (kernel) printk("generic_file_buffered_write_ex() 2 status = %d\n", status);
+	}
 	if (likely(status >= 0)) {
 		written += status;
 		*ppos = pos + status;
@@ -2318,8 +2568,18 @@
 	if (unlikely(file->f_flags & O_DIRECT) && written)
 		status = filemap_write_and_wait(mapping);
 
+//if (kernel) printk("generic_file_buffered_write_ex() Leaving: written = %d, status = %d\n", written, status);
 	return written ? written : status;
 }
+EXPORT_SYMBOL(generic_file_buffered_write_ex);
+
+ssize_t
+generic_file_buffered_write(struct kiocb *iocb, const struct iovec *iov,
+		unsigned long nr_segs, loff_t pos, loff_t *ppos,
+		size_t count, ssize_t written)
+{
+	return generic_file_buffered_write_ex(iocb, iov, nr_segs, pos, ppos, count, written, 0, 0);
+}
 EXPORT_SYMBOL(generic_file_buffered_write);
 
 static ssize_t
diff -Naur linux-2.6.24.4/mm/shmem.c linux-2.6.24.4-oxnas/mm/shmem.c
--- linux-2.6.24.4/mm/shmem.c	2008-03-25 02:49:18.000000000 +0800
+++ linux-2.6.24.4-oxnas/mm/shmem.c	2009-05-08 16:23:38.000000000 +0800
@@ -1681,7 +1681,7 @@
 		 * "pos" here (the actor routine has to update the user buffer
 		 * pointers and the remaining count).
 		 */
-		ret = actor(desc, page, offset, nr);
+		ret = actor(desc, &page, offset, nr);
 		offset += ret;
 		index += offset >> PAGE_CACHE_SHIFT;
 		offset &= ~PAGE_CACHE_MASK;
